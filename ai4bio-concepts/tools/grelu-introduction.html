<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Introduction to gReLU - AI4Bio Learning Hub</title>
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <style>
        body {
            font-family: 'Lato', sans-serif;
            background: linear-gradient(135deg, #f5f7fa 0%, #e8dcf5 100%);
            line-height: 1.8;
            color: #333;
            margin: 0;
            padding: 0;
        }
        .container {
            max-width: 1000px;
            margin: 0 auto;
            padding: 20px;
        }
        .navbar {
            background-color: #ffffff;
            border-bottom: 1px solid #e7e7e7;
            padding: 10px 0;
            margin-bottom: 30px;
        }
        .navbar-nav {
            list-style-type: none;
            padding: 0;
            margin: 0;
            display: flex;
            justify-content: center;
            align-items: center;
        }
        .navbar-nav li {
            margin: 0 15px;
        }
        .navbar-nav a {
            color: #666666;
            text-decoration: none;
            font-weight: bold;
            font-size: 16px;
        }
        .home-link {
            color: #5633AA !important;
        }
        .header {
            text-align: center;
            margin: 40px 0;
            padding: 30px;
            background: white;
            border-radius: 15px;
            box-shadow: 0 4px 15px rgba(86, 51, 170, 0.15);
        }
        .header h1 {
            color: #5633AA;
            font-size: 2.5em;
            margin-bottom: 10px;
        }
        .header .subtitle {
            font-size: 1.2em;
            color: #666;
            margin-bottom: 20px;
        }
        .content-section {
            background: white;
            padding: 30px;
            margin: 25px 0;
            border-radius: 15px;
            box-shadow: 0 4px 15px rgba(86, 51, 170, 0.1);
        }
        .content-section h2 {
            color: #5633AA;
            border-left: 4px solid #774BBE;
            padding-left: 15px;
            margin-bottom: 20px;
        }
        .content-section h3 {
            color: #774BBE;
            margin-top: 25px;
            margin-bottom: 15px;
        }
        .workflow-diagram {
            background: linear-gradient(135deg, #5633AA 0%, #774BBE 100%);
            color: white;
            padding: 30px;
            border-radius: 15px;
            margin: 30px 0;
        }
        .workflow-steps {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin-top: 20px;
        }
        .workflow-step {
            background: rgba(255,255,255,0.15);
            padding: 20px;
            border-radius: 10px;
            border: 2px solid rgba(255,255,255,0.3);
            text-align: center;
            transition: all 0.3s ease;
        }
        .workflow-step:hover {
            background: rgba(255,255,255,0.25);
            transform: translateY(-5px);
        }
        .workflow-step i {
            font-size: 2.5em;
            margin-bottom: 10px;
            display: block;
        }
        .feature-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin: 25px 0;
        }
        .feature-card {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 10px;
            border-left: 4px solid #774BBE;
            transition: all 0.3s ease;
        }
        .feature-card:hover {
            box-shadow: 0 5px 15px rgba(119, 75, 190, 0.3);
            transform: translateX(5px);
        }
        .feature-card h4 {
            color: #774BBE;
            margin-bottom: 10px;
        }
        .code-block {
            background: #2d2d2d;
            color: #f8f8f2;
            padding: 20px;
            border-radius: 10px;
            overflow-x: auto;
            margin: 20px 0;
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
            line-height: 1.6;
        }
        .code-block .comment {
            color: #6a9955;
        }
        .code-block .keyword {
            color: #9762D1;
        }
        .code-block .string {
            color: #ce9178;
        }
        .code-block .function {
            color: #dcdcaa;
        }
        .comparison-table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }
        .comparison-table th {
            background: #774BBE;
            color: white;
            padding: 15px;
            text-align: left;
        }
        .comparison-table td {
            padding: 12px 15px;
            border-bottom: 1px solid #e0e0e0;
        }
        .comparison-table tr:hover {
            background: #f8f9fa;
        }
        .highlight-box {
            background: #f5ebff;
            border-left: 4px solid #9762D1;
            padding: 15px;
            margin: 20px 0;
            border-radius: 5px;
        }
        .info-box {
            background: #e8dcf5;
            border-left: 4px solid #5633AA;
            padding: 15px;
            margin: 20px 0;
            border-radius: 5px;
        }
        .success-box {
            background: #f0e8ff;
            border-left: 4px solid #774BBE;
            padding: 15px;
            margin: 20px 0;
            border-radius: 5px;
        }
        .use-case {
            background: linear-gradient(135deg, #f5ebff 0%, #e8dcf5 100%);
            padding: 20px;
            border-radius: 10px;
            margin: 20px 0;
        }
        .resources-section {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 15px;
            margin: 20px 0;
        }
        .resource-link {
            background: white;
            padding: 15px;
            border-radius: 10px;
            text-align: center;
            text-decoration: none;
            color: #774BBE;
            font-weight: bold;
            transition: all 0.3s ease;
            border: 2px solid #774BBE;
        }
        .resource-link:hover {
            background: #774BBE;
            color: white;
            transform: translateY(-3px);
            box-shadow: 0 5px 15px rgba(119, 75, 190, 0.3);
        }
        .resource-link i {
            display: block;
            font-size: 2em;
            margin-bottom: 10px;
        }
        ul {
            padding-left: 20px;
        }
        ul li {
            margin-bottom: 10px;
        }
        @media (max-width: 768px) {
            .header h1 {
                font-size: 2em;
            }
            .workflow-steps {
                grid-template-columns: 1fr;
            }
        }
    </style>
</head>
<body>
    <nav class="navbar">
        <div class="container">
            <ul class="navbar-nav">
                <li><a href="../index.html" class="home-link"><i class="fas fa-arrow-left"></i> Back to Learning Hub</a></li>
            </ul>
        </div>
    </nav>

    <div class="container">
        <div class="header">
            <h1>üß¨ Introduction to gReLU</h1>
            <p class="subtitle">A Comprehensive Framework for DNA Sequence Modeling and Design</p>
            <p style="color: #666; font-size: 0.95em;">Learn how gReLU unifies the entire deep learning workflow for genomics - from data preprocessing to model interpretation and sequence design</p>
        </div>

        <div class="content-section">
            <h2><i class="fas fa-lightbulb"></i> What is gReLU?</h2>
            <p><strong>gReLU</strong> (Genomic Regulatory Element Learning Utilities) is an open-source Python framework developed by Genentech that provides a unified platform for building, training, and applying deep learning models to DNA sequences. Published in Nature Methods (2025), it addresses a major challenge in computational genomics: the lack of interoperability between different tools and models.</p>
            
            <div class="highlight-box">
                <strong><i class="fas fa-star"></i> Why gReLU Matters:</strong> Before gReLU, researchers had to switch between incompatible tools, write custom code for each task, and couldn't easily combine or compare models. gReLU changes this by providing one comprehensive framework for the entire workflow.
            </div>

            <h3>Key Problems gReLU Solves</h3>
            <div class="feature-grid">
                <div class="feature-card">
                    <h4><i class="fas fa-puzzle-piece"></i> Fragmentation</h4>
                    <p>No more juggling multiple incompatible tools. Everything is in one framework.</p>
                </div>
                <div class="feature-card">
                    <h4><i class="fas fa-code"></i> Custom Code</h4>
                    <p>Minimal custom code needed. Focus on science, not software engineering.</p>
                </div>
                <div class="feature-card">
                    <h4><i class="fas fa-exchange-alt"></i> Interoperability</h4>
                    <p>Easy to compare models, fine-tune for new tasks, and share results.</p>
                </div>
                <div class="feature-card">
                    <h4><i class="fas fa-history"></i> Modern Architecture</h4>
                    <p>Support for transformers, long-context models, and advanced interpretation.</p>
                </div>
            </div>
        </div>

        <div class="workflow-diagram">
            <h2 style="text-align: center; margin-bottom: 10px;">Complete gReLU Workflow</h2>
            <p style="text-align: center; opacity: 0.9; margin-bottom: 30px;">From raw genomic data to optimized sequences</p>
            <div class="workflow-steps">
                <div class="workflow-step">
                    <i class="fas fa-database"></i>
                    <h4>1. Data Input</h4>
                    <p>FASTA, BED, BigWig, BAM files</p>
                </div>
                <div class="workflow-step">
                    <i class="fas fa-filter"></i>
                    <h4>2. Preprocessing</h4>
                    <p>Filter, resize, match controls</p>
                </div>
                <div class="workflow-step">
                    <i class="fas fa-brain"></i>
                    <h4>3. Model Design</h4>
                    <p>CNNs, Transformers, U-Nets</p>
                </div>
                <div class="workflow-step">
                    <i class="fas fa-graduation-cap"></i>
                    <h4>4. Training</h4>
                    <p>Multi-task, profile modeling</p>
                </div>
                <div class="workflow-step">
                    <i class="fas fa-chart-line"></i>
                    <h4>5. Evaluation</h4>
                    <p>Metrics, predictions, validation</p>
                </div>
                <div class="workflow-step">
                    <i class="fas fa-search"></i>
                    <h4>6. Interpretation</h4>
                    <p>ISM, TF-MoDISco, attention</p>
                </div>
                <div class="workflow-step">
                    <i class="fas fa-dna"></i>
                    <h4>7. Variant Analysis</h4>
                    <p>SNPs, indels, effect sizes</p>
                </div>
                <div class="workflow-step">
                    <i class="fas fa-flask"></i>
                    <h4>8. Design</h4>
                    <p>Optimize sequences</p>
                </div>
            </div>
        </div>

        <div class="content-section">
            <h2><i class="fas fa-tools"></i> Core Features</h2>

            <h3>1. Data Input & Processing</h3>
            <p>gReLU accepts genomic data in standard formats and provides powerful preprocessing:</p>
            <ul>
                <li><strong>Input formats:</strong> DNA sequences, genomic coordinates, functional data (BigWig, BAM)</li>
                <li><strong>Automatic loading:</strong> Fetch sequences and annotations from public databases</li>
                <li><strong>Preprocessing:</strong> Filter sequences, remove blacklisted regions, generate GC-matched controls</li>
                <li><strong>PyTorch datasets:</strong> Built-in classes with batching, augmentation, normalization</li>
            </ul>



            <h3>2. Model Architectures</h3>
            <p>gReLU provides customizable architectures ranging from simple to state-of-the-art:</p>
            
            <table class="comparison-table">
                <thead>
                    <tr>
                        <th>Architecture</th>
                        <th>Best For</th>
                        <th>Key Features</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>DilatedConvModel</strong></td>
                        <td>Local patterns</td>
                        <td>Fast, interpretable, BPNet-style</td>
                    </tr>
                    <tr>
                        <td><strong>Transformer Models</strong></td>
                        <td>Long-range interactions</td>
                        <td>Attention mechanisms, 100kb+ context</td>
                    </tr>
                    <tr>
                        <td><strong>U-Net</strong></td>
                        <td>Segmentation tasks</td>
                        <td>Skip connections, multi-scale features</td>
                    </tr>
                    <tr>
                        <td><strong>Hybrid Models</strong></td>
                        <td>Complex tasks</td>
                        <td>CNN + Transformer, GRU layers</td>
                    </tr>
                </tbody>
            </table>



            <h3>3. Training & Evaluation</h3>
            <p>Flexible training for multiple task types with comprehensive evaluation:</p>
            
            <div class="feature-grid">
                <div class="feature-card">
                    <h4>Task Types</h4>
                    <p>‚Ä¢ Single/multi-task regression<br>
                    ‚Ä¢ Binary/multi-class classification<br>
                    ‚Ä¢ Segmentation<br>
                    ‚Ä¢ Profile prediction</p>
                </div>
                <div class="feature-card">
                    <h4>Training Features</h4>
                    <p>‚Ä¢ PyTorch Lightning integration<br>
                    ‚Ä¢ Weights & Biases logging<br>
                    ‚Ä¢ Hyperparameter sweeps<br>
                    ‚Ä¢ Transfer learning</p>
                </div>
                <div class="feature-card">
                    <h4>Evaluation Metrics</h4>
                    <p>‚Ä¢ Correlation, MSE, MAE<br>
                    ‚Ä¢ AUPRC, AUROC<br>
                    ‚Ä¢ Accuracy, F1 score<br>
                    ‚Ä¢ Custom metrics</p>
                </div>
                <div class="feature-card">
                    <h4>Special Features</h4>
                    <p>‚Ä¢ Example weighting<br>
                    ‚Ä¢ Data augmentation<br>
                    ‚Ä¢ Checkpointing with metadata<br>
                    ‚Ä¢ Reproducible configs</p>
                </div>
            </div>



            <h3>4. Model Interpretation</h3>
            <p>Understand what your model learned with comprehensive interpretation tools:</p>

            <div class="info-box">
                <strong><i class="fas fa-info-circle"></i> Why Interpretation Matters:</strong> Deep learning models are often "black boxes." gReLU's interpretation tools help you understand which sequences are important, what regulatory grammar the model learned, and whether its predictions are biologically meaningful.
            </div>

            <ul>
                <li><strong>Sequence importance:</strong> ISM (in silico mutagenesis), saliency, DeepLift/SHAP</li>
                <li><strong>Motif discovery:</strong> TF-MoDISco to find learned regulatory motifs</li>
                <li><strong>Motif scanning:</strong> Scan sequences with known PWMs to annotate important regions</li>
                <li><strong>Regulatory grammar:</strong> Test motif syntax by generating synthetic sequences</li>
                <li><strong>Attention visualization:</strong> For transformers, see which regions interact</li>
            </ul>



            <h3>5. Variant Effect Prediction</h3>
            <p>Prioritize functional genetic variants with robust statistical testing:</p>

            <ul>
                <li><strong>Input:</strong> SNPs, indels, or any sequence variants in standard formats</li>
                <li><strong>Processing:</strong> Automatic extraction of reference/alternate allele sequences</li>
                <li><strong>Effect size:</strong> Compare predictions between alleles</li>
                <li><strong>Robustness:</strong> Data augmentation and statistical testing</li>
                <li><strong>Interpretation:</strong> PWM scanning to identify disrupted/created motifs</li>
            </ul>

            <div class="success-box">
                <strong><i class="fas fa-check-circle"></i> Real Performance:</strong> In the gReLU paper, a simple convolutional model achieved AUPRC of 0.27 for identifying functional variants, while Enformer from the model zoo achieved 0.60 - dramatically outperforming previous methods (gkmSVM: 0.19).
            </div>



            <h3>6. Sequence Design</h3>
            <p>Optimize DNA sequences for desired properties using your trained models:</p>

            <div class="feature-grid">
                <div class="feature-card">
                    <h4>Directed Evolution</h4>
                    <p>Iteratively mutate sequences, similar to experimental directed evolution</p>
                </div>
                <div class="feature-card">
                    <h4>Gradient-Based</h4>
                    <p>Use backpropagation to find optimal sequences efficiently</p>
                </div>
                <div class="feature-card">
                    <h4>Constraints</h4>
                    <p>Control GC content, preserve motifs, limit editable positions</p>
                </div>
                <div class="feature-card">
                    <h4>Multi-Objective</h4>
                    <p>Optimize for multiple cell types or conditions simultaneously</p>
                </div>
            </div>



            <div class="use-case">
                <h4><i class="fas fa-microscope"></i> Real Example: PPIF Enhancer Design</h4>
                <p>The gReLU paper demonstrated designing a monocyte-specific enhancer for the PPIF gene. Using directed evolution with the Borzoi model:</p>
                <ul>
                    <li>Started with a known enhancer 61.7 kb upstream of PPIF</li>
                    <li>Made 20 base edits to maximize monocyte vs T cell expression</li>
                    <li>Achieved 41.76% increase in monocyte expression, only 16.75% in T cells</li>
                    <li>Analysis revealed new CEBP motifs - consistent with known biology</li>
                    <li>Validated with orthogonal chromatin accessibility models</li>
                </ul>
            </div>

            <h3>7. Model Zoo</h3>
            <p>Access pre-trained, state-of-the-art models without training from scratch:</p>

            <div class="info-box">
                <strong><i class="fas fa-cloud"></i> Available on Weights & Biases:</strong> The gReLU model zoo contains widely applicable models including Enformer (long-range predictions across 5,313 tracks) and Borzoi (RNA-seq coverage prediction). Each model includes code, datasets, and training logs.
            </div>

            <ul>
                <li><strong>Enformer:</strong> 200kb context, predicts gene expression and chromatin state</li>
                <li><strong>Borzoi:</strong> RNA-seq coverage profiles across multiple cell types</li>
                <li><strong>ChromBPNet:</strong> Base-resolution chromatin accessibility</li>
                <li><strong>Custom models:</strong> Easy to add your own to share with the community</li>
            </ul>



            <h3>8. Prediction Transform Layers</h3>
            <p>A unique gReLU innovation for working with complex multi-task, long-context models:</p>

            <div class="highlight-box">
                <strong><i class="fas fa-magic"></i> The Innovation:</strong> Previous tools could only interpret models with simple scalar outputs. Prediction transforms let you modify a model's output to compute derived quantities - like cell-type differences or exon-vs-intron ratios - enabling interpretation, variant analysis, and design for any function of the model's predictions.
            </div>

            <ul>
                <li><strong>Aggregate:</strong> Sum or average predictions over genomic regions</li>
                <li><strong>Specificity:</strong> Compute differences between cell types</li>
                <li><strong>Custom functions:</strong> Any derived metric you can imagine</li>
                <li><strong>Applications:</strong> Works seamlessly with interpretation, variant prediction, and design</li>
            </ul>
        </div>

        <div class="content-section">
            <h2><i class="fas fa-rocket"></i> Getting Started with gReLU</h2>

            <h3>Installation</h3>
            <p>Install gReLU via pip or from source on GitHub.</p>

            <h3>Quick Start Example</h3>
            <p>The gReLU framework provides a simple workflow: load a pre-trained model from the zoo, make predictions on sequences, interpret the model's learned patterns, predict variant effects, and design optimized sequences.</p>

            <div class="resources-section">
                <a href="https://github.com/Genentech/gReLU" class="resource-link" target="_blank">
                    <i class="fab fa-github"></i>
                    GitHub Repository
                </a>
                <a href="https://genentech.github.io/gReLU/" class="resource-link" target="_blank">
                    <i class="fas fa-book"></i>
                    Documentation
                </a>
                <a href="https://github.com/Genentech/gReLU/tree/main/docs/tutorials" class="resource-link" target="_blank">
                    <i class="fas fa-graduation-cap"></i>
                    Tutorials
                </a>
                <a href="https://wandb.ai/grelu/" class="resource-link" target="_blank">
                    <i class="fas fa-database"></i>
                    Model Zoo
                </a>
                <a href="https://doi.org/10.1038/s41592-025-02868-z" class="resource-link" target="_blank">
                    <i class="fas fa-file-alt"></i>
                    Nature Methods Paper
                </a>
            </div>
        </div>

        <div class="content-section">
            <h2><i class="fas fa-flask"></i> Key Use Cases</h2>

            <div class="use-case">
                <h4>1. Prioritizing Functional Variants</h4>
                <p><strong>Challenge:</strong> GWAS identifies thousands of variants - which are functionally important?</p>
                <p><strong>Solution:</strong> Use gReLU to predict the regulatory impact of each variant. Train a model on relevant cell type data or use a pre-trained model from the zoo. The paper showed this works well for prioritizing dsQTLs.</p>
            </div>

            <div class="use-case">
                <h4>2. Designing Cell-Type-Specific Enhancers</h4>
                <p><strong>Challenge:</strong> You want to activate a gene in specific cell types for gene therapy.</p>
                <p><strong>Solution:</strong> Use gReLU's sequence design tools with a multi-task model to optimize an enhancer for your target cell type while minimizing off-target effects. The PPIF example demonstrated this works.</p>
            </div>

            <div class="use-case">
                <h4>3. Understanding Regulatory Grammar</h4>
                <p><strong>Challenge:</strong> What regulatory "rules" did my model learn?</p>
                <p><strong>Solution:</strong> Use TF-MoDISco to discover motifs, generate synthetic sequences with varied motif arrangements, and test how spacing and orientation affect predictions.</p>
            </div>

            <div class="use-case">
                <h4>4. Comparing Model Architectures</h4>
                <p><strong>Challenge:</strong> Should I use a convolutional model or a transformer?</p>
                <p><strong>Solution:</strong> gReLU makes it easy to train different architectures on the same data and compare their performance. The paper showed Enformer outperformed a convolutional model for variant prediction (AUPRC 0.60 vs 0.27).</p>
            </div>
        </div>

        <div class="content-section">
            <h2><i class="fas fa-chart-line"></i> Advantages Over Alternatives</h2>

            <table class="comparison-table">
                <thead>
                    <tr>
                        <th>Feature</th>
                        <th>gReLU</th>
                        <th>Selene / Kipoi / Janggu</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>Transformer support</strong></td>
                        <td>‚úÖ Full support</td>
                        <td>‚ùå Limited or none</td>
                    </tr>
                    <tr>
                        <td><strong>Long-context models</strong></td>
                        <td>‚úÖ 100kb+ sequences</td>
                        <td>‚ö†Ô∏è Typically <1kb</td>
                    </tr>
                    <tr>
                        <td><strong>Profile prediction</strong></td>
                        <td>‚úÖ Native support</td>
                        <td>‚ùå Scalar outputs only</td>
                    </tr>
                    <tr>
                        <td><strong>Sequence design</strong></td>
                        <td>‚úÖ Evolution + gradients</td>
                        <td>‚ö†Ô∏è Limited tools</td>
                    </tr>
                    <tr>
                        <td><strong>Variant analysis</strong></td>
                        <td>‚úÖ With augmentation</td>
                        <td>‚úÖ Basic support</td>
                    </tr>
                    <tr>
                        <td><strong>Model zoo</strong></td>
                        <td>‚úÖ State-of-the-art models</td>
                        <td>‚ö†Ô∏è Varies</td>
                    </tr>
                    <tr>
                        <td><strong>Interpretation</strong></td>
                        <td>‚úÖ Comprehensive</td>
                        <td>‚ö†Ô∏è Limited</td>
                    </tr>
                    <tr>
                        <td><strong>Data augmentation</strong></td>
                        <td>‚úÖ Most comprehensive</td>
                        <td>‚ö†Ô∏è Basic</td>
                    </tr>
                </tbody>
            </table>
        </div>

        <div class="content-section">
            <h2><i class="fas fa-exclamation-triangle"></i> Limitations & Future Directions</h2>
            <p>The gReLU authors acknowledge several areas for future development:</p>
            <ul>
                <li><strong>Longer contexts:</strong> Efficient architectures (Hyena, Mamba) for modeling >200kb sequences</li>
                <li><strong>Additional design algorithms:</strong> More sophisticated optimization methods</li>
                <li><strong>Multi-species training:</strong> Efficient training on larger, multi-species datasets</li>
                <li><strong>Bias modeling:</strong> Better handling of technical biases in genomic assays</li>
                <li><strong>Personalized genomes:</strong> Modeling individual genomes with variants</li>
            </ul>
        </div>
    </div>
</body>
</html>
